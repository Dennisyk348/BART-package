{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pymc3\n",
    "import imodels\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bartpy2.sklearnmodel import SklearnModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feature_names = imodels.get_clean_dataset('breast_cancer', data_source='imodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.16113493324115327\n"
     ]
    }
   ],
   "source": [
    "# Assuming SklearnModel exists in bartpy2\n",
    "model = SklearnModel(n_trees=50, n_burn=200, n_samples=200)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29221325, 0.33582939, 0.29955711, 0.23180746, 0.48532823,\n",
       "       0.27527773, 0.14107054, 0.33500485, 0.13282632, 0.10602598,\n",
       "       0.17717608, 0.18127687, 0.74704655, 0.20634628, 0.45976231,\n",
       "       0.45581675, 0.1758603 , 0.13514411, 0.34870905, 0.23225181,\n",
       "       0.55053908, 0.36229912, 0.10424293, 0.20770407, 0.45387185,\n",
       "       0.21898169, 0.1797071 , 0.23075426, 0.50723522, 0.1758603 ,\n",
       "       0.20162393, 0.19431384, 0.35082985, 0.67603768, 0.11638495,\n",
       "       0.12364467, 0.14204919, 0.56268163, 0.29351534, 0.56372784,\n",
       "       0.37553377, 0.46563249, 0.7332341 , 0.11494959, 0.20380027,\n",
       "       0.17288797, 0.26622594, 0.52839261, 0.39716886, 0.58196454,\n",
       "       0.27319129, 0.28128109, 0.15860567, 0.34300403, 0.2800706 ,\n",
       "       0.22307055, 0.19237895, 0.21984915, 0.23075426, 0.5783731 ,\n",
       "       0.4958261 , 0.2208643 , 0.15862839, 0.43022042, 0.30676655,\n",
       "       0.27118428, 0.68228759, 0.1350158 , 0.28737866, 0.39385217])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7781217750257997\n",
      "F1 Score: 0.39999999999999997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "y_pred_proba = model.predict(X_test)  \n",
    "y_pred = (y_pred_proba > 0.5).astype(int) \n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"AUC:\", auc)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_burn': 100, 'n_samples': 200, 'n_trees': 50}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for the best parameters using GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_trees': (10, 20, 50),\n",
    "              'n_burn':(50,100,200),\n",
    "              'n_samples':(100,200,500)}\n",
    "grid_search = GridSearchCV(model, parameters)\n",
    "grid_search.fit(X, y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7801857585139318\n",
      "F1 Score: 0.39999999999999997\n"
     ]
    }
   ],
   "source": [
    "model_choose = SklearnModel(n_trees=50, n_burn=100, n_samples=200)\n",
    "model_choose.fit(X_train, y_train)\n",
    "\n",
    "predictions_choose = model_choose.predict(X_test)\n",
    "y_pred_proba_choose = model_choose.predict(X_test)  \n",
    "y_pred_choose = (y_pred_proba_choose > 0.5).astype(int) \n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred_proba_choose)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_choose)\n",
    "\n",
    "print(\"AUC:\", auc)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
